---
title: "Final Project"
output:
  pdf_document: default
  html_document: default
date: "2024-12-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Required Packages

```{r}
library(lme4)
library(brms)
library(ggplot2)
library(glmmTMB)
library(broom.mixed)
library(performance)
library(DHARMa)
library(dplyr)
library(ggeffects)
library(splines)
```

## Load the Dataset

```{r}
# Load the VerbAgg dataset
data("VerbAgg", package = "lme4")
```


```{r}
# Display structure of the dataset
str(VerbAgg)

# Summarize the dataset
summary(VerbAgg)
```

---

## Description of the Questions

**Objective of Data Collection**: The VerbAgg dataset was collected to investigate the determinants of verbal aggression in hypothetical scenarios. Specifically, the study aimed to understand how individual characteristics, situational contexts, and behavior types influence the likelihood of aggressive responses (`r2`):

**Demographic Influences**: Does `gender` affect the likelihood of verbal aggression? Are males or females more likely to respond aggressively?
**Behavioral Context**: How does the type of aggressive behavior (`btype`, e.g., cursing, scolding, shouting) influence the likelihood of a participant exhibiting aggression?
**Situational Context** (`situ`): Are participants more likely to respond aggressively when the situation involves themselves (`self`) compared to others (`other`)?
**Mode of Response** (`mode`): Is there a difference between participantsâ€™ hypothetical desires (what they want to do) and their actual behaviors (what they would do) in terms of aggression?
**Inter-Individual Variability**: Is there substantial variability in aggression tendencies between individuals (`id`), and can this variability be captured through random effects?

---

## Modeling Approach and Methods

To address these questions, the original data collectors used a **Generalized Linear Mixed Model (GLMM)** with the following components:

### Response Variable:

`r2`: A binary indicator of whether the participant responded aggressively (`Y` for Yes, `N` for No).

### Fixed Effects:

`gender`: A demographic predictor indicating the participant's gender (male or female).
`btype`: Categorical predictor for behavior type (curse, scold, shout).
`mode`: Categorical predictor for response mode (want vs. do).
`situ`: Categorical predictor for situational context (self vs. other).

### Random Effects:

`(1 | id)`: A random intercept for each individual (`id`), accounting for differences in baseline aggression tendencies between participants.

### Conditional Distribution:

The response variable `r2` is modeled using a **binomial distribution** (since it is binary) with a **logit link function**.

### Model Equation

We specify a Generalized Linear Mixed Model (GLMM) to analyze the likelihood of verbal aggression (\(r2 = 1\)) as a function of individual and situational predictors, accounting for inter-individual variability. The maximal model is written as:

$$
\text{logit}(P(r2 = 1)) = \beta_0 + \beta_1 \cdot \text{gender} + \beta_2 \cdot \text{btype} + \beta_3 \cdot \text{mode} + \beta_4 \cdot \text{situ} + u_{\text{id}}
$$

Where:
- \( \beta_0 \): Overall intercept.
- \( \beta_1, \beta_2, \beta_3, \beta_4 \): Coefficients for fixed effects (gender, behavior type, mode, situational context).
- \( u_{\text{id}} \sim \mathcal{N}(0, \sigma^2) \): Random intercept capturing inter-individual variability.

---

## Specification and Justification of Three Packages

For the analysis of the **VerbAgg** dataset, we will use three packages: two Frequentist approaches (`lme4` and `glmmTMB`), and one Bayesian (`brms`).

### 1. `lme4` (Frequentist Approach)

#### Description
- **`lme4`** is a widely used R package for fitting linear and generalized linear mixed models (GLMMs) using maximum likelihood estimation (MLE).

#### Why Use It?
- **Efficiency**: Uses **Laplace approximation** by default, providing a balance of speed and accuracy for GLMMs.
- **Flexibility**: Supports a wide range of response distributions and link functions (e.g., binomial with logit link for binary responses like `r2`).
- **Reliability**: It is well-documented, robust, and commonly used in mixed-effects modeling.

#### When to Use
- Fit the maximal Frequentist model to establish baseline results.
- Use it for model comparison and diagnostics (e.g., singularity issues, fixed effect significance).


### 2. `glmmTMB` (Frequentist Approach)

#### Description
`glmmTMB` is an R package for fitting generalized linear mixed models using the Template Model Builder (TMB) framework. It extends the capabilities of `lme4` by supporting additional distributions, zero-inflation, and overdispersion.

#### Why Use It?

- It uses **Laplace approximation** by default, similar to `lme4`.
- **Flexibility**: Supports a broader range of response distributions, including:
  - Negative Binomial (for overdispersed count data).
  - Beta and zero-inflated models.
  - Gaussian, Binomial, Poisson, and more.
- **Advanced Modeling**: Allows for zero-inflation or hurdle models to account for datasets with excessive zeros.
- **Stability**: Efficient optimization routines make it robust for larger datasets or models with more parameters.
- **Random Effects**: Supports more complex structures, including nested and crossed random effects.

#### When to Use
- Use when the dataset exhibits **overdispersion** or **zero-inflation** (issues that `lme4` cannot directly address).
- Fit complex GLMMs requiring advanced response distributions or mixed-effects structures.
- Use as a fallback when `lme4` runs into singularity or convergence issues, or when diagnostics suggest model inadequacy.
- Particularly useful for ecological, medical, or hierarchical data with excessive zeros or overdispersed counts.

### 3. `brms` (Bayesian Approach)

#### Description
- **`brms`** is an interface to Stan for Bayesian regression models, allowing flexible and user-friendly mixed model fitting.

#### Why Use It?
- It uses **Markov Chain Monte Carlo (MCMC)** sampling via Stan.
- **Flexibility**: Supports custom priors, complex random effects, and non-standard distributions.
- **Bayesian Inference**: Incorporates uncertainty in parameter estimates through posterior distributions.
- **Diagnostics**: Provides convergence diagnostics (e.g., R-hat values) and posterior predictive checks.
- **Extensibility**: Supports complex models, including multilevel and hierarchical Bayesian models.

#### When to Use
- Use to refine the analysis with prior knowledge (e.g., weakly informative priors).
- Address model uncertainty or convergence issues in the Frequentist approach.

### Summary
By combining `lme4`, `glmmTMB`, and `brms`, we ensure robust modeling across frequentist and Bayesian paradigms. This approach enables flexibility to handle complex data structures (e.g., overdispersion, zero-inflation), provides rigorous diagnostics, and allows for uncertainty quantification, offering a comprehensive analytical framework.

## Exploratory Plots

```{r}
# Plot 1: Distribution of Aggressive Responses
ggplot(VerbAgg, aes(x = r2)) +
  geom_bar(fill = "lightblue") +
  labs(title = "Distribution of Aggressive Responses",
       x = "Aggressive Response (N = No, Y = Yes)",
       y = "Count") +
  theme_minimal()
```
The data is relatively balanced between the two categories, with slightly more non-aggressive responses (`N`) compared to aggressive responses (`Y`), which is helpful for binary classification modeling.

```{r}
# Plot 2: Aggressive Response by Gender
ggplot(VerbAgg, aes(x = Gender, fill = r2)) +
  geom_bar(position = "dodge") +
  labs(title = "Aggressive Response by Gender",
       x = "Gender",
       y = "Count",
       fill = "Aggressive Response") +
  scale_fill_manual(values = c("N" = "lightpink", "Y" = "lightblue")) +
  theme_minimal()
```
Females (`F`) have a higher number of both aggressive (`Y`) and non-aggressive (`N`) responses compared to males (`M`). Proportionally, the difference between `N` and `Y` responses appears larger for males (`M`).

```{r}
# Plot 3: Aggressive Response by Mode
ggplot(VerbAgg, aes(x = mode, fill = r2)) +
  geom_bar(position = "dodge") +
  labs(title = "Aggressive Response by Mode",
       x = "Mode of Response (Want vs. Do)",
       y = "Count",
       fill = "Aggressive Response") +
  scale_fill_manual(values = c("N" = "lightgreen", "Y" = "lightcoral")) +
  theme_minimal()
```
In the "want" mode, there are more aggressive (`Y`) responses than non-aggressive (`N`) responses. In the "do" mode, non-aggressive responses (`N`) are more frequent than aggressive ones (`Y`).

```{r}
# Plot 4: Anger Scores by Aggressive Response
ggplot(VerbAgg, aes(x = r2, y = Anger, fill = r2)) +
  geom_boxplot() +
  labs(title = "Anger Scores by Aggressive Response",
       x = "Aggressive Response (N = No, Y = Yes)",
       y = "Anger Score") +
  scale_fill_manual(values = c("N" = "skyblue", "Y" = "salmon")) +
  theme_minimal()
```
Median anger scores are slightly higher for aggressive (`Y`) responses than for non-aggressive (`N`) responses. There is considerable overlap in the anger score distributions between the two groups.

## Fit the Models

```{r}
# Fit the GLMM using lme4
model_lme4 <- glmer(r2 ~ Gender + btype + mode + situ + (1 | id),
                    data = VerbAgg, family = binomial(link = "logit"))

# Summarize the model
summary(model_lme4)
```

```{r}
# Fit the GLMM using glmmTMB
model_glmmTMB <- glmmTMB(r2 ~ Gender + btype + mode + situ + (1 | id),
                         data = VerbAgg, family = binomial(link = "logit"))

# Summarize the model
summary(model_glmmTMB)
```

```{r}
# Specify priors (optional)
priors <- c(
  prior(normal(0, 5), class = "b"),  # Priors for fixed effects
  prior(normal(0, 10), class = "Intercept"),  # Prior for intercept
  prior(exponential(1), class = "sd"))  # Priors for random effects

# Fit the GLMM using brms
model_brms <- brm(r2 ~ Gender + btype + mode + situ + (1 | id),
                  data = VerbAgg, family = bernoulli(link = "logit"),
                  prior = priors, chains = 4, iter = 2000, seed = 123)

# Summarize the model
summary(model_brms)
```

### Comparison of Fixed Effects

- `GenderM` has a positive coefficient (`~0.30`), suggesting males have slightly higher odds of responding aggressively, though it is not statistically significant (`p > 0.05` or 95% CI contains `0`).
- `btypescold` and `btypeshout` have large negative coefficients (`~-1.06` and `-2.04`, respectively), indicating that scolding and shouting reduce the odds of aggression compared to cursing.
- `modedo` has a negative coefficient (`~-0.67`), suggesting that participants are less likely to act aggressively when reporting what they "would do", compared to "want to do."
- `situself` has a negative coefficient (`~-1.03`), indicating participants are less aggressive in situations involving themselves than others.

### Random Effects

Compare the **standard deviation** of the random intercept for `id` (individuals):

- `lme4`: Std.Dev = 1.333.
- `glmmTMB`: Std.Dev = 1.333.
- `brms`: Std.Dev = 1.35 (posterior mean with credible interval [1.22, 1.48]).

The random effects are very similar across the three models, indicating that the variability in baseline aggression among individuals is consistent.

### Goodness-of-Fit Metrics

Compare **AIC** and **BIC** values from `lme4` and `glmmTMB` (Bayesian models like brms do not provide AIC/BIC by default):

`lme4`: AIC = 8249.4, BIC = 8298.0.
`glmmTMB`: AIC = 8249.4, BIC = 8298.0.

Both frequentist models fit the data equally well based on AIC/BIC.

## Diagnostics for Models
```{r}
# Check model performance
check_model(model_lme4)

# Residual diagnostics
check_residuals(model_lme4)
```

**Posterior Predictive Check:** Model-predicted intervals cover observed data points, indicating a good fit.
**Binned Residuals:** Most residuals fall within the error bounds, but there are some deviations at higher probabilities of aggression. This may indicate slight misspecification at the extremes.
**Influential Observations:** Points outside the contour lines suggest potential influential observations. These should be further investigated for their impact on the model.
**Collinearity:** Variance Inflation Factor (`VIF`) values are low (`< 5`), indicating no significant collinearity among predictors.
**Uniformity of Residuals:** Residuals align well with the expected uniform distribution, suggesting a good model fit.
**Normality of Random Effects:** The random effects (`id`) follow the theoretical quantiles closely, supporting the assumption of normality.

```{r}
# Simulate residuals for DHARMa diagnostics
res_lme4 <- simulateResiduals(fittedModel = model_lme4)

# Plot residual diagnostics
plot(res_lme4)

# Test residuals for uniformity
testUniformity(res_lme4)

# Test for overdispersion
testDispersion(res_lme4)

# Test for zero inflation
testZeroInflation(res_lme4)
```

**QQ Plot of Residuals:** The residuals follow the 1:1 line closely, indicating a good fit. The Kolmogorov-Smirnov (KS) test, dispersion test, and outlier test all show non-significant results (`p > 0.05`), confirming no substantial deviations from model assumptions.
**Residuals vs. Predicted Values:** The residuals are evenly distributed around 0 across predicted probabilities, with no obvious patterns or trends. This suggests the model captures the data well.

```{r}
# Simulate residuals for DHARMa diagnostics
res_glmmTMB <- simulateResiduals(fittedModel = model_glmmTMB)

# Plot residual diagnostics
plot(res_glmmTMB)

# Test residuals for uniformity
testUniformity(res_glmmTMB)

# Test for overdispersion
testDispersion(res_glmmTMB)

# Test for zero inflation
testZeroInflation(res_glmmTMB)
```
**Q-Q Plot Residuals:** The residuals follow the 1:1 diagonal line, confirming no systematic deviation from the expected uniform distribution. Tests for uniformity (Kolmogorov-Smirnov), dispersion, and outliers are non-significant (`p > 0.05`), confirming that residuals are well-behaved.
**Dispersion Test:** Dispersion ratio (`1.0002`) and `p-value = 1` indicate no overdispersion, suggesting the variance in the data is well-captured by the model.
**Zero-Inflation Test:** The observed-to-expected ratio of zeros is close to 1 (`ratioObsSim = 1.0009`), with a non-significant `p-value = 0.976`. This confirms that there is no excessive zero-inflation in the model.

```{r}
# Posterior predictive check with density overlay
pp_check(model_brms, type = "dens_overlay")
```
The model's predicted distributions align closely with the observed data, showing that the model captures the underlying structure of the data well.
The model fits the data effectively, with no visible discrepancies between observed and predicted distributions.

## Adjustments and Refinements

```{r}
# Create spline terms for a continuous predictor, e.g., "Anger"
VerbAgg$spline_Anger <- ns(VerbAgg$Anger, df = 4)
```

###  1. `lme4`: Addressing Deviations in Residuals at Extremes by Adding Interaction Terms

Adding the interaction `btype:mode` allows the model to capture potential variations in how the behavioral type (`btype`) affects aggressive responses (`r2`) depending on the mode of response (`mode`).

```{r}
model_lme4_refined <- glmer(r2 ~ Gender + btype * mode + situ + spline_Anger + (1 | id), 
                            data = VerbAgg, family = binomial(link = "logit"),
                            control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
```

```{r}
# Check model performance
check_model(model_lme4_refined)

# Residual diagnostics
check_residuals(model_lme4_refined)
```

```{r}
# Simulate residuals for DHARMa diagnostics
res_lme4_refined <- simulateResiduals(fittedModel = model_lme4_refined)

# Plot residual diagnostics
plot(res_lme4_refined)
```

Based on the diagnostic results, the refined model with the interaction term (`btype:mode`) including spline terms (`spline_Anger`) does not improve significantly compared to the simpler model (`model_lme4`). Therefore, I would revert to the simpler model (`model_lme4`).

### 2. `glmmTMB`: Refit with Alternative Link Functions

```{r}
model_glmmTMB_probit <- glmmTMB(r2 ~ Gender + btype + mode + situ + spline_Anger + (1 | id), 
                                data = VerbAgg, family = binomial(link = "probit"))
```

```{r}
# Simulate residuals for DHARMa diagnostics
res_glmmTMB_probit <- simulateResiduals(fittedModel = model_glmmTMB_probit)

# Plot residual diagnostics
plot(res_glmmTMB_probit)
```
The diagnostics for the `probit` model (`model_glmmTMB_probit`) including spline terms (`spline_Anger`) do not show significant improvement over the simpler `logit` model (`model_lme4`). Thus, I will keep using the `logit` model (`model_lme4`).

### 3. `brms` Model with spline

```{r}
model_brms_spline <- brm(
  r2 ~ Gender + btype + mode + situ + spline_Anger + (1 | id),
  data = VerbAgg, family = bernoulli(link = "logit"),
  prior = set_prior("normal(0, 5)", class = "b"))
```

```{r}
pp_check(model_brms_spline, type = "dens_overlay")
```
The diagnostics for the model (`model_brms_spline`) including spline terms (`spline_Anger`) do not show significant improvement over the simpler model (`model_brms`). Thus, I will keep using the simpler model (`model_brms`).

## Conclusions

### Coefficient plot

```{r}
# Extract tidy summaries
tidy_lme4 <- tidy(model_lme4)
tidy_glmmTMB <- tidy(model_glmmTMB)
tidy_brms <- tidy(model_brms, effects = "fixed")

# Add model names
tidy_lme4$model <- "lme4"
tidy_glmmTMB$model <- "glmmTMB"
tidy_brms$model <- "brms"

# Combine into one data frame
coefficients <- bind_rows(tidy_lme4, tidy_glmmTMB, tidy_brms)

# Filter for fixed effects only
coefficients <- coefficients %>%
  filter(effect == "fixed") %>%
  mutate(term = factor(term, levels = unique(term)))
```

```{r}
# Coefficient plot
ggplot(coefficients, aes(x = estimate, y = term, color = model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = estimate - std.error, xmax = estimate + std.error), 
                position = position_dodge(width = 0.5), width = 0.2) +
  theme_minimal() +
  labs(
    title = "Coefficient Estimates from Models",
    x = "Estimate",
    y = "Predictors",
    color = "Model")
```
Since the predictors have different units, the coefficient plot should be scaled.

```{r}
coefficients <- coefficients %>%
  mutate(scaled_estimate = estimate / std.error)  # Scale by standard error for comparability

ggplot(coefficients, aes(x = scaled_estimate, y = term, color = model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(xmin = scaled_estimate - 1, xmax = scaled_estimate + 1), 
                position = position_dodge(width = 0.5), width = 0.2) +
  theme_minimal() +
  labs(
    title = "Standardized Coefficient Estimates from Models",
    x = "Scaled Coefficient (Standardized)",
    y = "Predictors",
    color = "Model")
```

### Effects Plots

```{r}
# Predicted Probabilities (for Frequentist Models)

# Generate predicted effects for lme4 and glmmTMB models
pred_lme4 <- ggeffects::ggpredict(model_lme4, terms = c("btype", "mode"))
pred_glmmTMB <- ggeffects::ggpredict(model_glmmTMB, terms = c("btype", "mode"))

# Plot predicted probabilities for lme4
plot(pred_lme4) + 
  ggtitle("Predicted Probabilities (lme4)") + 
  theme_minimal()

# Plot predicted probabilities for glmmTMB
plot(pred_glmmTMB) + 
  ggtitle("Predicted Probabilities (glmmTMB)") + 
  theme_minimal()
```

```{r}
# Generate conditional effects
conditional_effects_brms <- conditional_effects(model_brms)

# Plot conditional effects
plot(conditional_effects_brms, points = TRUE)
```

